{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from scipy.io import savemat\n",
    "import shutil\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:23:13.322278Z",
     "start_time": "2023-11-13T20:23:13.292854Z"
    }
   },
   "id": "a1291f40a8d24f87"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "np.random.seed(101)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:23:13.334468Z",
     "start_time": "2023-11-13T20:23:13.297043Z"
    }
   },
   "id": "d54b59a6939d35c"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "base_path_structured = \"/Users/benhoskings/Documents/Datasets/Fusion\"\n",
    "train_path_structured = os.path.join(base_path_structured, \"train_set\")\n",
    "test_path_structured = os.path.join(base_path_structured, \"test_set\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:23:13.335456Z",
     "start_time": "2023-11-13T20:23:13.300913Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "emotions_affect_net = pd.Series([\"Neutral\", \"Happy\", \"Sad\", \"Surprise\", \"Fear\", \"Disgust\", \"Anger\", \"Contempt\"])\n",
    "emotions_aff_wild = pd.Series([\"Neutral\",\"Anger\",\"Disgust\",\"Fear\",\"Happy\",\"Sad\",\"Surprise\",\"Other\"])\n",
    "\n",
    "for set in [\"train_set\", \"test_set\"]:\n",
    "    for em in pd.unique(pd.concat([emotions_affect_net, emotions_aff_wild])):\n",
    "        if not os.path.isdir(os.path.join(base_path_structured, set, em)):\n",
    "            os.mkdir(os.path.join(base_path_structured, set, em))\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:23:13.347881Z",
     "start_time": "2023-11-13T20:23:13.304194Z"
    }
   },
   "id": "dd43205d7b98ca2a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def get_sample_ids(emotions, counts, max_size=None, seed=None):\n",
    "    # counts = [24882, 3750, 3803, 6378, 134414, 74874, 25459, 14090]\n",
    "    label_count = dict(zip(emotions, counts))\n",
    "    \n",
    "    if max_size:\n",
    "        max_size = min([max_size, min(label_count.values())])\n",
    "    else:\n",
    "        max_size = min(label_count.values())\n",
    "        \n",
    "    ids1 = np.empty((max_size, 0), np.int32)\n",
    "    ids2 = np.empty((0, 1), np.int32)\n",
    "    \n",
    "    for idx, emotion in enumerate(emotions):\n",
    "        file_count = label_count[emotion]\n",
    "        emIds = np.random.permutation(np.arange(file_count))[:max_size]\n",
    "        start_idx = sum(counts[:idx])\n",
    "        ids1 = np.append(ids1, np.expand_dims(emIds, axis=1), axis=1)\n",
    "        ids2 = np.append(ids2, start_idx + emIds)\n",
    "        \n",
    "    return ids1, ids2, class_count\n",
    "\n",
    "def num_string(num):\n",
    "    if num != 0:\n",
    "        return f\"0000{int(num)}\"[int(math.log10(num)):]\n",
    "    else:\n",
    "        return \"00000\"\n",
    "\n",
    "def is_corrupted(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img.verify() # verify that it is, in fact an image\n",
    "        return False\n",
    "    except:\n",
    "        return True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:23:13.348006Z",
     "start_time": "2023-11-13T20:23:13.310931Z"
    }
   },
   "id": "a12c4787a3e3fffb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aff Wild Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b95868299e1ce279"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "base_path_raw = \"/Users/benhoskings/Documents/Datasets/Aff-Wild-V2/Provided\"\n",
    "label_path = os.path.join(base_path_raw, \"Third ABAW Annotations/MTL_Challenge\")\n",
    "image_path_raw = os.path.join(base_path_raw, \"Images\")\n",
    "\n",
    "train_labels = pd.read_csv(os.path.join(label_path, \"train_set.txt\"), index_col=0)\n",
    "train_labels = train_labels.loc[train_labels['expression'] >= 0]\n",
    "train_labels = train_labels.sort_values(by=[\"expression\"])\n",
    "corrupt = np.array([is_corrupted(os.path.join(image_path_raw, \"batch1\", path)) for path in train_labels.index])\n",
    "train_labels = train_labels.loc[np.logical_not(corrupt)]\n",
    "train_labels = train_labels[~train_labels.index.duplicated(keep='first')]\n",
    "# print(len(pd.unique(train_labels.index)))\n",
    "\n",
    "aff_wild_class_count = train_labels.value_counts(subset=['expression']) \n",
    "class_count = np.array(aff_wild_class_count, dtype=np.int64)\n",
    "class_labels = np.array([id[0] for id in aff_wild_class_count.index], dtype=np.uint16)\n",
    "class_count = class_count[np.argsort(class_labels)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:23:26.403966Z",
     "start_time": "2023-11-13T20:23:13.315037Z"
    }
   },
   "id": "cbfb5717e0dd5e0f"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expression\n",
      "0             2053\n",
      "1             2053\n",
      "2             2053\n",
      "3             2053\n",
      "4             2053\n",
      "5             2053\n",
      "6             2053\n",
      "7             2053\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "id1, id2, sample_count = get_sample_ids(emotions_aff_wild, class_count)\n",
    "train_subset = train_labels.iloc[id2, :]\n",
    "print(train_subset.value_counts(subset=['expression']) )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:23:26.411476Z",
     "start_time": "2023-11-13T20:23:26.404139Z"
    }
   },
   "id": "be6083c4b5476f7a"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class_counts = np.zeros((len(emotions_aff_wild), 1))\n",
    "\n",
    "for im_path in train_subset.index:\n",
    "    values = train_subset.loc[im_path]\n",
    "    emotion_idx = int(values[\"expression\"])\n",
    "    emotion = emotions_aff_wild[emotion_idx]\n",
    "    class_idx = class_counts[emotion_idx]\n",
    "    sample_path = os.path.join(train_path_structured, emotion, \"AW-\" + num_string(class_idx.item()))\n",
    "    # savemat(f\"{sample_path}.mat\", values.to_dict())\n",
    "    shutil.copy(os.path.join(image_path_raw, \"batch1\", im_path), f\"{sample_path}.png\")\n",
    "    class_counts[emotion_idx] += 1\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:23:30.704275Z",
     "start_time": "2023-11-13T20:23:26.410904Z"
    }
   },
   "id": "aa32bfad237225d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AffectNet Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f56a7bd4e6bac3e"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "base_path_raw = \"/Users/benhoskings/Documents/Datasets/AffectNet/Data/train_set-1\"\n",
    "has_image = np.array([os.path.isfile(f\"{base_path_raw}/images/{idx}.jpg\") for idx in range(414796)])\n",
    "has_emotion = np.array([os.path.isfile(f\"{base_path_raw}/annotations/{idx}_exp.npy\") for idx in range(414796)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:25:01.469787Z",
     "start_time": "2023-11-13T20:23:30.704755Z"
    }
   },
   "id": "90e04e57e1ff84ef"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "train_labels_affect_net = pd.DataFrame(index=range(414796))\n",
    "train_labels_affect_net[\"has_image\"] = has_image\n",
    "train_labels_affect_net[\"has_emotion\"] = has_emotion\n",
    "train_labels_affect_net = train_labels_affect_net.loc[np.logical_and(train_labels_affect_net[\"has_image\"] == True, train_labels_affect_net[\"has_emotion\"] == True)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:25:01.478391Z",
     "start_time": "2023-11-13T20:25:01.473247Z"
    }
   },
   "id": "3e367fcd00071509"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "image_paths = [f\"{base_path_raw}/images/{idx}.jpg\" for idx in train_labels_affect_net.index]\n",
    "affect_net_emotions = np.array([np.load(f\"{base_path_raw}/annotations/{idx}_exp.npy\") for idx in train_labels_affect_net.index], dtype=np.uint8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:26:45.366621Z",
     "start_time": "2023-11-13T20:25:01.514756Z"
    }
   },
   "id": "37943c094da65282"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "train_labels_affect_net[\"image_path\"] = image_paths\n",
    "train_labels_affect_net[\"emotion\"] = affect_net_emotions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:26:45.380638Z",
     "start_time": "2023-11-13T20:26:45.376841Z"
    }
   },
   "id": "fed6bccb9986f27e"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "train_labels_affect_net = train_labels_affect_net.set_index(\"image_path\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:26:45.387411Z",
     "start_time": "2023-11-13T20:26:45.381071Z"
    }
   },
   "id": "a2cbd7977ff2b370"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "train_labels_affect_net = train_labels_affect_net.sort_values(by=[\"emotion\"])\n",
    "train_labels_affect_net = train_labels_affect_net[~train_labels_affect_net.index.duplicated(keep='first')]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:26:45.437033Z",
     "start_time": "2023-11-13T20:26:45.389344Z"
    }
   },
   "id": "7d74a862f10609a4"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "affect_net_class_count = train_labels_affect_net.value_counts(subset=['emotion']) \n",
    "class_count = np.array(affect_net_class_count)\n",
    "class_labels = np.array([id for id in affect_net_class_count.index]).flatten()\n",
    "class_count = class_count[np.argsort(class_labels)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:26:45.442291Z",
     "start_time": "2023-11-13T20:26:45.437603Z"
    }
   },
   "id": "4f0976b8057bcb45"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "0          3750\n",
      "1          3750\n",
      "2          3750\n",
      "3          3750\n",
      "4          3750\n",
      "5          3750\n",
      "6          3750\n",
      "7          3750\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "id1, id2, sample_count = get_sample_ids(emotions=emotions_affect_net, counts=class_count)\n",
    "train_subset = train_labels_affect_net.iloc[id2, :]\n",
    "print(train_subset.value_counts(subset=['emotion']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:26:45.452443Z",
     "start_time": "2023-11-13T20:26:45.443539Z"
    }
   },
   "id": "54509e58ca81dab2"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "837bbd305a49f6dd"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class_counts = np.zeros((len(emotions_affect_net), 1))\n",
    "\n",
    "for im_path in train_subset.index:\n",
    "    values = train_subset.loc[im_path]\n",
    "    emotion_idx = int(values[\"emotion\"])\n",
    "    emotion = emotions_affect_net[emotion_idx]\n",
    "    class_idx = class_counts[emotion_idx]\n",
    "    sample_path = os.path.join(train_path_structured, emotion, \"AN-\" + num_string(class_idx.item()))\n",
    "    # savemat(f\"{sample_path}.mat\", values.to_dict())\n",
    "    shutil.copy(im_path, f\"{sample_path}.png\")\n",
    "    class_counts[emotion_idx] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T20:26:57.714889Z",
     "start_time": "2023-11-13T20:26:45.452753Z"
    }
   },
   "id": "f237d470f9cae408"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
